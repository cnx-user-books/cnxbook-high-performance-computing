<document xmlns="http://cnx.rice.edu/cnxml">
  <title>Subroutine Profiling</title>
<metadata xmlns:md="http://cnx.rice.edu/mdml">
  <md:content-id>m33713</md:content-id>
  <md:title>Subroutine Profiling</md:title>
  <md:abstract/>
  <md:uuid>bde36c2c-6e37-45f9-8b45-6baa5916110c</md:uuid>
</metadata>

<content>
      <para id="id1167623882232">Sometimes you want more detail than the overall timing of the application. But you don’t have time to modify the code to insert several hundred <emphasis effect="italics">etime</emphasis> calls into your code. Profiles are also very useful when you have been handed a strange 20,000-line application program and told to figure out how it works and then improve its performance.</para>
      <para id="id1167617349262">Most compilers provide a facility to automatically insert timing calls into your code at the entry and exit of each routine at compile time. While your program runs, the entry and exit times are recorded and then dumped into a file. A separate utility summarizes the execution patterns and produces a report that shows the percentage of the time spent in each of your routines and the library routines.</para>
      <para id="id1167615535185">The profile gives you a sense of the shape of the execution profile. That is, you can see that 10% of the time is spent in subroutine A, 5% in subroutine B, etc. Naturally, if you add all of the routines together they should account for 100% of the overall time spent. From these percentages you can construct a picture — a <emphasis effect="italics">profile</emphasis> — of how execution is distributed when the program runs. Though not representative of any particular profiling tool, the histograms in <link target-id="id1167616191624"/> and <link target-id="id1167630064798"/> depict these percentages, sorted from left to right, with each vertical column representing a different routine. They help illustrate different profile shapes.</para>
      <figure id="id1167616191624"><title>Sharp profile — dominated by routine 1</title><media id="id1167616191624_media" alt="This figure is a histogram, with routines on the horizontal axis and % time on the vertical axis. For routines of value 1, the histogram shows a % time value of 65. For routines of value 2, the histogram shows a % time value of 20. For routines of value 3, the histogram shows a % time value of 10. For routines of value 4, the histogram shows a % time value of 5. For routines of value 5, the histogram shows a % time value of approximately 2. Above the histograms is a dashed curve that follows the decreasing trend of the histogram as the number of routines increases.">
          <image mime-type="image/png" src="../../media/graphics1-9ce2.png" id="id1167616191624__onlineimage" height="363" width="700"/>
        </media>
      </figure>
      
      <para id="id1167615487040">A <emphasis effect="italics">sharp profile</emphasis> says that most of the time is spent in one or two procedures, and if you want to improve the program’s performance you should focus your efforts on tuning those procedures. A minor optimization in a heavily executed line of code can sometimes have a great effect on the overall runtime, given the right opportunity. A <emphasis effect="italics">flat profile</emphasis>,<footnote id="id1167615348767">The term “flat profile” is a little overloaded. We are using it to describe a profile that shows an even distribution of time throughout the program. You will also see the label flat profile used to draw distinction from a call graph profile, as described below.</footnote> on the other hand, tells you that the runtime is spread across many routines, and effort spent optimizing any one or two will have little benefit in speeding up the program. Of course, there are also programs whose execution profile falls somewhere in the middle.</para>
      <figure id="id1167630064798"><title>Flat profile — no routine predominates</title><media id="id1167630064798_media" alt="This figure is a histogram, with routines on the horizontal axis and % time on the vertical axis. For routines of value 1, the histogram shows a % time value of approximately 22. For routines of value 2, the histogram shows a % time value of 20. For routines of value 3, the histogram shows a % time value of approximately 18. For routines of value 4, the histogram shows a % time value of approximately 22. For routines of value 5, the histogram shows a % time value of approximately 18. Above the histograms is a dashed curve that follows the decreasing trend of the histogram as the number of routines increases.">
          <image mime-type="image/png" src="../../media/graphics2-dd7d.png" id="id1167630064798__onlineimage" height="368" width="700"/>
        </media>
      </figure>
      
      <para id="id1167615256723">We cannot predict with absolute certainty what you are likely to find when you profile your programs, but there are some general trends. For instance, engineering and scientific codes built around matrix solutions often exhibit very sharp profiles. The runtime is dominated by the work performed in a handful of routines. To tune the code, you need to focus your efforts on those routines to make them more efficient. It may involve restructuring loops to expose parallelism, providing hints to the compiler, or rearranging memory references. In any case, the challenge is tangible; you can see the problems you have to fix.</para>
      <para id="id1167615502136">There are limits to how much tuning one or two routines will improve your runtime, of course. An often quoted rule of thumb is <emphasis effect="italics">Amdahl’s Law</emphasis>, derived from remarks made in 1967 by one of the designers of the IBM 360 series, and founder of Amdahl Computer, Gene Amdahl. Strictly speaking, his remarks were about the performance potential of parallel computers, but people have adapted Amdahl’s Law to describe other things too. For our purposes, it goes like this: Say you have a program with two parts, one that can be optimized so that it goes infinitely fast and another that can’t be optimized at all. Even if the optimizable portion makes up 50% of the initial runtime, at best you will be able to cut the total runtime in half. That is, your runtime will eventually be dominated by the portion that can’t be optimized. This puts an upper limit on your expectations when tuning.</para>
      <para id="id1167614712741">Even given the finite return on effort suggested by Amdahl’s Law, tuning a program with a sharp profile can be rewarding. Programs with flat profiles are much more difficult to tune. These are often system codes, nonnumeric applications, and varieties of numerical codes without matrix solutions. It takes a global tuning approach to reduce, to any justifiable degree, the runtime of a program with a flat profile. For instance, you can sometimes optimize instruction cache usage, which is complicated because of the program’s equal distribution of activity among a large number of routines. It can also help to reduce subroutine call overhead by folding callees into callers. Occasionally, you can find a memory reference problem that is endemic to the whole program — and one that can be fixed all at once.</para>
      <para id="id1167615501208">When you look at a profile, you might find an unusually large percentage of time spent in the library routines such as <code display="inline">log</code>, <code display="inline">exp</code>, or <code display="inline">sin</code>. Often these functions are done in software routines rather than inline. You may be able to rewrite your code to eliminate some of these operations. Another important pattern to look for is when a routine takes far longer than you expect. Unexpected execution time may indicate you are accessing memory in a pattern that is bad for performance or that some aspect of the code cannot be optimized properly.</para>
      <para id="id1167615568941">In any case, to get a profile, you need a profiler. One or two <emphasis effect="italics">subroutine profilers</emphasis> come standard with the software development environments on all UNIX machines. We discuss two of them: <emphasis effect="italics">prof </emphasis>and <emphasis effect="italics">gprof</emphasis>. In addition, we mention a few line-by-line profilers. Subroutine profilers can give you a general overall view of where time is being spent. You probably should start with <emphasis effect="italics">prof</emphasis>, if you have it (most machines do). Otherwise, use <emphasis effect="italics">gprof</emphasis>. After that, you can move to a line-by- line profiler if you need to know which statements take the most time.</para>
      <section id="id1167615576249">
        <title>prof</title>
        <para id="id1167615451950"><emphasis effect="italics">prof</emphasis> is the most common of the UNIX profiling tools. In a sense, it is an extension of the compiler, linker, and object libraries, plus a few extra utilities, so it is hard to look at any one thing and say “this profiles your code.” <emphasis effect="italics">prof</emphasis> works by periodically sampling the program counter as your application runs. To enable profiling, you must recompile and relink using the <code display="inline">–p</code> flag. For example, if your program has two modules, <emphasis effect="italics">stuff.c</emphasis> and <emphasis effect="italics">junk.c</emphasis>, you need to compile and link according to the following code:</para>
        <code id="id1167617838232" display="block"><newline/>
      % cc stuff.c -p -O -c
      % cc junk.c -p -O -c
      % cc stuff.o junk.o -p -o stuff
    </code>
        <para id="id1167617329945">This creates a stuff binary that is ready for profiling. You don’t need to do anything special to run it. Just treat it normally by entering <code display="inline">stuff</code>. Because runtime statistics are being gathered, it takes a little longer than usual to execute.<footnote id="id1167612595912">Remember: code with profiling enabled takes longer to run. You should recompile and relink the whole thing <emphasis effect="italics">without</emphasis> the <code display="inline">–p</code> flag when you have finished profiling.</footnote> At completion, there is a new file called <emphasis effect="italics">mon.out</emphasis> in the directory where you ran it. This file contains the history of <emphasis effect="italics">stuff</emphasis> in binary form, so you can’t look at it directly. Use the <emphasis effect="italics">prof </emphasis>utility to read <emphasis effect="italics">mon.out</emphasis> and create a profile of <emphasis effect="italics">stuff</emphasis>. By default, the information is written to your screen on standard output, though you can easily redirect it to a file:</para>
        <code id="id1167615587911" display="block"><newline/>
      % prof stuff &gt; stuff.prof
    </code>
        <para id="id1167612696568">To explore how the <emphasis effect="italics">prof</emphasis> command works, we have created the following ridiculous little application, <emphasis effect="italics">loops.c</emphasis>. It contains a main routine and three subroutines for which you can predict the time distribution just by looking at the code.</para>
        <code id="id1167612618648" display="block"><newline/>
      main () {
          int l;
          for (l=0;l&lt;1000;l++) {
              if (l == 2*(l/2)) foo ();
              bar();
              baz();
          }
      }
      foo (){
          int j;
          for (j=0;j&lt;200;j++)
      }
      bar () {
          int i;
          for (i=0;i&lt;200;i++);
      }
      baz () {
          int k;
          for (k=0;k&lt;300;k++);
      }
    </code>
        <para id="id1167614668507">Again, you need to compile and link <emphasis effect="italics">loops</emphasis> with the <code display="inline">–p</code> flag, run the program, and then run the <emphasis effect="italics">prof</emphasis> utility to extract a profile, as follows:</para>
        <code id="id1167614433333" display="block"><newline/>
      % cc loops.c -p -o loops
      % ./loops
      % prof loops &gt; loops.prof
    </code>
        <para id="id1167615347549">The following example shows what a <emphasis effect="italics">loops.prof</emphasis> should look like. There are six columns.</para>
        <code id="eip-453" display="block"><newline/>
      %Time Seconds Cumsecs #Calls msec/call Name
       56.8    0.50    0.50   1000    0.500  _baz
       27.3    0.24    0.74   1000    0.240  _bar
       15.9    0.14    0.88    500    0.28   _foo 
        0.0    0.00    0.88      1    0.     _creat
        0.0    0.00    0.88      2    0.     _profil
        0.0    0.00    0.88      1    0.     _main
        0.0    0.00    0.88      3    0.     _getenv
        0.0    0.00    0.88      1    0.     _strcpy
        0.0    0.00    0.88      1    0.     _write</code>
        <para id="id1167615611691">The columns can be described as follows:</para>
        <list id="id1167614931721" list-type="bulleted">
          <item><code display="inline">%Time</code> Percentage of CPU time consumed by this routine</item>
          <item><code display="inline">Seconds</code> CPU time consumed by this routine</item>
          <item><code display="inline">Cumsecs</code> A running total of time consumed by this and all preceding routines in the list</item>
          <item><code display="inline">Calls</code> The number of times this particular routine was called</item>
          <item><code display="inline">msec/call</code> Seconds divided by number of calls giving the average length of time taken by each invocation of the routine</item>
          <item><code display="inline">Name</code> The name of this routine</item>
        </list>
        <para id="id1167615154588">The top three routines listed are from <emphasis effect="italics">loops.c</emphasis> itself. You can see an entry for the “main” routine more than halfway down the list. Depending on the vendor, the names of the routines may contain leading or trailing underscores, and there will always be some routines listed you don’t recognize. These are contributions from the C library and possibly the FORTRAN libraries, if you are using FORTRAN. Profiling also introduces some overhead into the run, and often shows up as one or two subroutines in the <emphasis effect="italics">prof</emphasis> output. In this case, the entry for <code display="inline">_profil</code> represents code inserted by the linker for collecting runtime profiling data.</para>
        <para id="id1167614415864">If it was our intention to tune <emphasis effect="italics">loops</emphasis>, we would consider a profile like the one in the figure above to be a fairly good sign. The lead routine takes 50% of the runtime, so at least there is a chance we could do something with it that would have a significant impact on the overall runtime. (Of course with a program as trivial as <emphasis effect="italics">loops</emphasis>, there is plenty we can do, since <emphasis effect="italics">loops</emphasis> does nothing.)</para>
      </section>
      <section id="id1167614486234">
        <title>gprof</title>
        <para id="id1167614768094">Just as it’s important to know how time is distributed when your program runs, it’s also valuable to be able to tell who called who in the list of routines. Imagine, for instance, if something labeled <code display="inline">_exp</code> showed up high in the list in the prof output. You might say: “Hmmm, I don’t remember calling anything named <code display="inline">exp()</code>. I wonder where that came from.” A call tree helps you find it.</para>
        <para id="id1167615552991">Subroutines and functions can be thought of as members of a family tree. The top of the tree, or root, is actually a routine that precedes the main routine you coded for the application. It calls your main routine, which in turn calls others, and so on, all the way down to the leaf nodes of the tree. This tree is properly known as a <emphasis effect="italics">call graph</emphasis>.<footnote id="id1167614558211">It doesn’t have to be a tree. Any subroutine can have more than one parent. Furthermore, recursive subroutine calls introduce cycles into the graph, in which a child calls one of its parents.</footnote> The relationship between routines and nodes in the graph is one of parents and children. Nodes separated by more than one hop are referred to as ancestors and descendants.</para>
        <para id="id1167615235527">Figure 6-4 graphically depicts the kind of call graph you might see in a small application. <code display="inline">main</code> is the parent or ancestor of most of the rest of the routines. <code display="inline">G</code> has two parents, <code display="inline">E</code> and <code display="inline">C</code>. Another routine, <code display="inline">A</code>, doesn’t appear to have any ancestors or descendants at all. This problem can happen when routines are not compiled with profiling enabled, or when they aren’t invoked with a subroutine call — such as would be the case if <code display="inline">A</code> were an exception handler.</para>
        <para id="id1167614569055">The UNIX profiler that can extract this kind of information is called <emphasis effect="italics">gprof</emphasis>. It replicates the abilities of <emphasis effect="italics">prof</emphasis>, plus it gives a call graph profile so you can see who calls whom, and how often. The call graph profile is handy if you are trying to figure out how a piece of code works or where an unknown routine came from, or if you are looking for candidates for subroutine inlining.</para>
        <para id="id1167613972096">To use call graph profiling you need go through the same steps as with <emphasis effect="italics">prof</emphasis>, except that a <code display="inline">–pg</code> flag is substituted for the <code display="inline">–p</code> flag.<footnote id="id1167612661184">On HP machines, the flag is <code display="inline">–G</code>.</footnote> Additionally, when it comes time to produce the actual profile, you use the <emphasis effect="italics">gprof</emphasis> utility instead of <emphasis effect="italics">prof</emphasis>. One other difference is that the name of the statistics file is <emphasis effect="italics">gmon.out</emphasis> instead of <emphasis effect="italics">mon.out</emphasis>:</para>
        <code id="id1167615483734" display="block"><newline/>
      % cc -pg stuff.c -c
      % cc stuff.o -pg -o stuff
      % stuff
      % gprof stuff &gt; stuff.gprof
    </code>
        <figure id="id1167615387546"><title>Simple call graph</title><media id="id1167615387546_media" alt="This figure is a flow chart. The top of the flowchart is a box labeled, Main. From this box are two lines, one connected to a box labeled, B, and the other connected to a box labeled, C. From the B box are two lines, one connected to a box labeled, D, and one connected to a box labeled, E. From the E box is a line connected to a box labeled, G. From the C box is a line connected to the same box, G. To the right of the flowchart is a box labeled, A, with no connections.">
            <image mime-type="image/png" src="../../media/graphics3-7ef4.png" id="id1167615387546__onlineimage" height="391" width="700"/>
          </media>
        </figure>
        
        
        <para id="eip-456">The output from <code>gprof</code> is divided into three sections:</para><list id="id1167627410813" list-type="bulleted">
          <item>Call graph profile</item>
          <item>Timing profile</item>
          <item>Index</item>
        </list>
        <para id="id1167615599337">The first section textually maps out the call graph. The second section lists routines, the percentage of time devoted to each, the number of calls, etc. (similar to <emphasis effect="italics">prof</emphasis> ). The third section is a cross reference so that you can locate routines by number, rather than by name. This section is especially useful for large applications because routines are sorted based on the amount of time they use, and it can be difficult to locate a particular routine by scanning for its name. Let’s invent another trivial application to illustrate how <emphasis effect="italics">gprof</emphasis> works. <link target-id="id1167616187270"/> shows a short piece of FORTRAN code, along with a diagram of how the routines are connected together. Subroutines <code display="inline">A</code> and <code display="inline">B</code> are both called by <code display="inline">MAIN</code>, and, in turn, each calls <code display="inline">C</code>. The following example shows a section of the output from <emphasis effect="italics">gprof</emphasis> ’s call graph profile:<footnote id="id1167615219435">In the interest of conserving space, we clipped out the section most relevant to our discussion and included it in this example. There was a lot more to it, including calls of setup and system routines, the likes of which you will see when you run <emphasis effect="italics">gprof</emphasis>.</footnote></para>
        <figure id="id1167616187270"><title>FORTRAN example</title><media id="id1167616187270_media" alt="This figure is a flow chart. The top of the flowchart is a box labeled, Main.  To the side of the Main box are four lines of code. Line one reads, program main. Line two reads, call a. Line three reads, call b. Line four reads, end. From this box are two lines, one connected to a box labeled, A, and the other connected to a box labeled, B. To the side of the A box are five lines of code. Line one reads, subroutine a. Line two reads, call c. Line three reads, do 10 i=1, 5000000. Line four reads, 10 continue. Line five reads, end. To the side of the B box are five lines of code. Line one reads, subroutine b. Line two reads, call c. Line three reads, do 10 i=1,10000000. Line four reads, 10 continue. Line five reads, end. Connected to the bottom of both box A and box B are arrows that point at a box labeled, C. To the side of the C box are four lines of code. Line one reads, subroutine c. Line two reads, do 10 i=1,5000000. Line three reads, 10 continue. Line four reads, end.">
            <image mime-type="image/png" src="../../media/graphics4-ab31.png" id="id1167616187270__onlineimage" height="428" width="699"/>
          </media>
        </figure>
        
        <code id="id1167615470278" display="block"><newline/>
                                          called/total      parents
      index  %time     self descendants   called+self   name       index 
                                          called/total      children
    
        ....                       ....                         ....
    
                       0.00          8.08      1/1          _main [2] 
      [3]    99.9      0.00          8.08      1        _MAIN_ [3]
                       3.23          1.62      1/1          _b_ [4]
                       1.62          1.62      1/1          _a_ [5]
    
      -----------------------------------------------
    
                       3.23          1.62      1/1          _MAIN_ [3] 
      [4]    59.9      3.23          1.62      1        _b_ [4]
                       1.62          0.00      1/2          _c_ [6]
    
      -----------------------------------------------
    
                       1.62          1.62      1/1          _MAIN_ [3] 
      [5]    40.0      1.62          1.62      1        _a_ [5]
                       1.62          0.00      1/2          _c_ [6]
    
      -----------------------------------------------
    
                       1.62          0.00      1/2          _a_ [5]
                       1.62          0.00      1/2          _b_ [4] 
      [6]    39.9      3.23          0.00      2        _c_ [6]
    </code>
        
        <para id="eip-737">Sandwiched between each set of dashed lines is information describing a given
routine and its relationship to parents and children. It is easy to tell which routine
the block represents because the name is shifted farther to the left than the others.
Parents are listed above, children below. As with <code>prof</code>, underscores are tacked
onto the labels.<footnote id="eip-id1170457275000">You may have noticed that there are two main routines: <code>_MAIN_</code> and <code>_main</code>. In a FORTRAN program, <code>_MAIN_</code> is the actual FORTRAN main routine. It’s called as a subroutine by <code>_main</code>, provided from a system library at link time. When you’re profiling C code, you won’t see <code>_MAIN_</code>.</footnote> A description of each of the columns follows:</para><list id="id1167615218971" list-type="bulleted"><item><code display="inline">index</code> You will notice that each routine name is associated with a number in brackets (<code display="inline">[n]</code>). This is a cross-reference for locating the routine elsewhere in the profile. If, for example, you were looking at the block describing <code display="inline">_MAIN_</code> and wanted to know more about one of its children, say <code display="inline">_a_</code>, you could find it by scanning down the left side of the page for its index, <code display="inline">[5]</code>.</item>
          <item><code display="inline">%time</code> The meaning of the <code display="inline">%time</code> field is a little different than it was for <emphasis effect="italics">prof</emphasis>. In this case it describes the percentage of time spent in this routine <emphasis effect="italics">plus</emphasis> the time spent in all of its children. It gives you a quick way to determine where the busiest sections of the call graph can be found.</item>
          <item><code display="inline">self</code> Listed in seconds, the <code display="inline">self</code> column has different meanings for parents, the routine in question, and its children. Starting with the middle entry — the routine itself — the <code display="inline">self</code> figure shows how much overall time was dedicated to the routine. In the case <code display="inline">_b_</code>, for instance, this amounts to 3.23 seconds.  
<newline/>
Each <code display="inline">self</code> column entry shows the amount of time that can be attributed to calls from the parents. If you look at routine <code display="inline">_c_</code>, for example, you will see that it consumed a total time of 3.23 seconds. But note that it had two parents: 1.62 seconds of the time was attributable to calls from <code display="inline">_a_</code>, and 1.62 seconds to <code display="inline">_b_</code>.
<newline/>
For the children, the <code display="inline">self</code> figure shows how much time was spent executing each child due to calls from this routine. The children may have consumed more time overall, but the only time accounted for is time-attributable to calls from this routine. For example, <code display="inline">_c_</code> accumulated 3.23 seconds overall, but if you look at the block describing <code display="inline">_b_</code>, you see <code display="inline">_c_</code> listed as a child with only 1.62 seconds. That’s the total time spent executing <code display="inline">_c_</code> on behalf of <code display="inline">_b_</code>.</item>
      

    <item><code display="inline">descendants</code> As with the <code display="inline">self</code> column, figures in the descendants column have different meanings for the routine, its parents, and children. For the routine itself, it shows the number of seconds spent in all of its descendants.
<newline/>
 For the routine’s parents, the descendants figure describes how much time spent in the routine can be traced back to calls by each parent. Looking at routine <code display="inline">_c_</code> again, you can see that of its total time, 3.23 seconds, 1.62 seconds were attributable to each of its two parents, <code display="inline">_a_</code> and <code display="inline">_b_</code>.
<newline/>
For the children, the descendants column shows how much of the child’s time can be attributed to calls from this routine. The child may have accumulated more time overall, but the only time displayed is time associated with calls from this routine.</item>
          <item><code display="inline">calls</code> The <code display="inline">calls</code> column shows the number of times each routine was invoked, as well as the distribution of those calls associated with both parents and children. Starting with the routine itself, the figure in the <code display="inline">calls</code> column shows the total number of entries into the routine. In situations where the routine called itself, you will also see a <emphasis effect="italics">+n</emphasis> immediately appended, showing that additional <emphasis effect="italics">n</emphasis> calls were made recursively.
<newline/>
Parent and child figures are expressed as ratios. For the parents, the ratio <emphasis effect="italics">m/n</emphasis> says “of the <emphasis effect="italics">n</emphasis> times the routine was called, <emphasis effect="italics">m</emphasis> of those calls came from this parent.” For the child, it says “of the <emphasis effect="italics">n</emphasis> times this child was called, <emphasis effect="italics">m</emphasis> of those calls came from this routine.”</item>
        </list>
      </section>
      <section id="id1167614480456">
        <title>gprof’s Flat Profile</title>
        <para id="id1167612592954">As we mentioned previously, <emphasis effect="italics">gprof</emphasis> also produces a timing profile (also called a “flat” profile, just to confuse things) similar to the one produced by <emphasis effect="italics">prof</emphasis>. A few of the fields are different from <emphasis effect="italics">prof</emphasis>, and there is some extra information, so it will help if we explain it briefly. The following example shows the first few lines from a <emphasis effect="italics">gprof</emphasis> flat profile for <emphasis effect="italics">stuff</emphasis>. You will recognize the top three routines from the original program. The others are library functions included at link-time.</para>
        <code id="id1167615245907" display="block"><newline/>
      %    cumulative     self              self     total
     time    seconds     seconds    calls  ms/call  ms/call  name
     39.9       3.23        3.23        2  1615.07  1615.07  _c_ [6]
     39.9       6.46        3.23        1  3230.14  4845.20  _b_ [4]
     20.0       8.08        1.62        1  1620.07  3235.14  _a_ [5]
      0.1       8.09        0.01        3     3.33     3.33  _ioctl [9]
      0.0       8.09        0.00       64     0.00     0.00  .rem [12]
      0.0       8.09        0.00       64     0.00     0.00  _f_clos [177]
      0.0       8.09        0.00       20     0.00     0.00  _sigblock [178]
      ...        ....       ....       .         .       .       ......
    </code>
        <para id="id1167614362301">Here’s what each column means:</para>
        <list id="id1167612704108" list-type="bulleted"><item><code display="inline">%time</code> Again, we see a field that describes the runtime for each routine as a percent- age of the overall time taken by the program. As you might expect, all the entries in this column should total 100% (nearly).</item>
          <item><code display="inline">cumulative</code> seconds For any given routine, the column called “cumulative seconds” tallies a running sum of the time taken by all the preceding routines plus its own time. As you scan towards the bottom, the numbers asymptotically approach the total runtime for the program.</item>
          <item><code display="inline">self</code> seconds Each routine’s individual contribution to the runtime.</item>
          <item><code display="inline">calls</code> The number of times this particular routine was called.</item>
          <item><code display="inline">self ms/call</code> Seconds spent inside the routine, divided by the number of calls. This gives the average length of time taken by each invocation of the routine. The figure is presented in milliseconds.</item>
          <item><code display="inline">total ms/call</code> Seconds spent inside the routine plus its descendants, divided by the number of calls.</item>
          <item><code display="inline">name</code> The name of the routine. Notice that the cross-reference number appears here too.</item>
        </list>
      </section>
      <section id="id1167617573991">
        <title>Accumulating the Results of Several gprof Runs</title>
        <para id="id1167615422193">It is possible to accumulate statistics from multiple runs so that you can get a picture of how a program is doing with a variety of data sets. For instance, say that you wanted to profile an application — call it <emphasis effect="italics">bar</emphasis> — with three different sets of input data. You could perform the runs separately, saving the <emphasis effect="italics">gmon.out</emphasis> files as you go, and then combine the results into a single profile at the end:</para>
        <code id="id1167615599105" display="block"><newline/>
      % f77 -pg bar.f -o bar
      % bar &lt; data1.input
      % mv gmon.out gmon.1
      % bar &lt; data2.input
      % mv gmon.out gmon.2
      % bar &lt; data3.input
      % gprof bar -s gmon.1 gmon.2 gmon.out &gt; gprof.summary.out
    </code>
        <para id="id1167613941429">In the example profile, each run along the way creates a new <emphasis effect="italics">gmon.out</emphasis> file that we renamed to make room for the next one. At the end, <emphasis effect="italics">gprof</emphasis> combines the infor- mation from each of the data files to produce a summary profile of <emphasis effect="italics">bar</emphasis> in the file <emphasis effect="italics">gprof.summary.out</emphasis>. Additionally (you don’t see it here), <emphasis effect="italics">gprof</emphasis> creates a file named <emphasis effect="italics">gmon.sum</emphasis> that contains the merged data from the original three data files. <emphasis effect="italics">gmon.sum</emphasis> has the same format as <emphasis effect="italics">gmon.out</emphasis>, so you can use it as input for other merged profiles down the road.</para>
        <para id="id1167615163681">In form, the output from a merged profile looks exactly the same as for an individual run. There are a couple of interesting things you will note, however. For one thing, the <code display="inline">main</code> routine appears to have been invoked more than once — one time for each run, in fact. Furthermore, depending on the application, multiple runs tend to either smooth the contour of the profile or exaggerate its features. You can imagine how this might happen. If a single routine is consistently called while others come and go as the input data changes, it takes on increasing importance in your tuning efforts.</para>
      </section>
      <section id="id1167614757306">
        <title>A Few Words About Accuracy</title>
        <para id="id1167614433798">For processors running at 600 MHz and more, the time between 60 Hz and 100 Hz samples is a veritable eternity. Furthermore, you can experience quantization errors when the sampling frequency is fixed, as is true of steady 1/100th or 1/60th of a second samples. To take an exaggerated example, assume that the timeline in <link target-id="id1167614746344"/> shows alternating calls to two subroutines, <code display="inline">BAR</code> and <code display="inline">FOO</code>. The tick marks represent the sample points for profiling.</para>
        <figure id="id1167614746344"><title>Quantization errors in profiling</title><media id="id1167614746344_media" alt="This figure is a line of alternating grey and dark grey sections. The grey sections are wider, and are labeled ..bar.., and the dark grey sections are labeled .foo.">
            <image mime-type="image/png" src="../../media/graphics5-2fda.png" id="id1167614746344__onlineimage" height="163" width="700"/>
          </media>
        </figure>
        
        <para id="id1167623772430"><code display="inline">BAR</code> and <code display="inline">FOO</code> take turns running. In fact, <code display="inline">BAR</code> takes more time than <code display="inline">FOO</code>. But because the sampling interval closely matches the frequency at which the two subroutines alternate, we get a quantizing error: most of the samples happen to be taken while <code display="inline">FOO</code> is running. Therefore, the profile tells us that <code display="inline">FOO</code> took more CPU time than <code display="inline">BAR</code>.</para>
        <para id="id1167614658647">We have described the tried and true UNIX subroutine profilers that have been available for years. In many cases, vendors have much better tools available for the asking or for a fee. If you are doing some serious tuning, ask your vendor representative to look into other tools for you.</para>
      </section>
   </content>
</document>
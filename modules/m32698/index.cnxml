<document xmlns="http://cnx.rice.edu/cnxml">
  <title>Exercises</title>
<metadata xmlns:md="http://cnx.rice.edu/mdml">
  <md:content-id>m32698</md:content-id>
  <md:title>Exercises</md:title>
  <md:abstract/>
  <md:uuid>81d8d8d7-4ef9-45f2-8926-473afee7fff5</md:uuid>
</metadata>
<featured-links>
  <!-- WARNING! The 'featured-links' section is read only. Do not edit below.
       Changes to the links section in the source will not be saved. -->
    <link-group type="supplemental">
      <link url="http://cnx.org/content/m32709/latest/" strength="3">Acknowledgements</link>
    </link-group>
  <!-- WARNING! The 'featured-links' section is read only. Do not edit above.
       Changes to the links section in the source will not be saved. -->
</featured-links>
<content>
<exercise id="id8999425">
        <problem id="oo-id9383613">
          <para id="id7887861">The following code segment traverses a pointer chain:
<code id="eip-id1170142702690" display="block">while ((p = (char *) *p) != NULL);</code>
          How will such a code interact with the cache if all the references fall within a small portion of memory? How will the code interact with the cache if references are stretched across many megabytes?</para>
        </problem>
      </exercise>
      <exercise id="id6813355">
        <problem id="oo-id9355012">
          <para id="id9292314">How would the code in <link target-id="id8999425"/> behave on a multibanked memory system that has no cache?</para>
        </problem>
      </exercise>
      <exercise id="id9311439">
        <problem id="oo-id9278593">
          <para id="id8788256">A long time ago, people regularly wrote self-modifying code — programs that wrote into instruction memory and changed their own behavior. What would be the implications of self-modifying code on a machine with a Harvard memory architecture?</para>
        </problem>
      </exercise>
      <exercise id="id9389116">
        <problem id="oo-id9186563">
          <para id="id9389119">Assume a memory architecture with an L1 cache speed of 10 ns, L2 speed of 30 ns, and memory speed of 200 ns. Compare the average memory system performance with (1) L1 80%, L2 10%, and memory 10%; and (2) L1 85% and memory 15%.</para>
        </problem>
      </exercise>
      <exercise id="id8671097">
        <problem id="oo-id8636059">
          <para id="id8671100">On a computer system, run loops that process arrays of varying length from 16 to 16 million:
<code id="eip-id1166732593462" display="block">ARRAY(I) = ARRAY(I) + 3</code>
How does the number of additions per second change as the array length changes? Experiment with <code>REAL*4</code>, <code>REAL*8</code>, <code>INTEGER*4</code>, and <code>INTEGER*8</code>.
</para>
<para id="eip-id1166731192986">
Which has more significant impact on performance: larger array elements or integer versus floating-point? Try this on a range of different computers.</para>
        </problem>
      </exercise>
      
      <exercise id="id9331114">
        <problem id="oo-id9355494">
          <para id="id9331117">Create a two-dimensional array of 1024×1024. Loop through the array with rows as the inner loop and then again with columns as the inner loop. Perform a simple operation on each element. Do the loops perform differently? Why? Experiment with different dimensions for the array and see the performance impact.</para>
        </problem>
      </exercise>
      <exercise id="id8814543">
        <problem id="oo-id8314603">
          <para id="id8814545">Write a program that repeatedly executes timed loops of different sizes to determine the cache size for your system.</para>
        </problem>
      </exercise>
  </content>
</document>
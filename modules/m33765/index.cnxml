<document xmlns="http://cnx.rice.edu/cnxml">
  <title>High Performance FORTRAN (HPF)</title>
<metadata xmlns:md="http://cnx.rice.edu/mdml">
  <md:content-id>m33765</md:content-id>
  <md:title>High Performance FORTRAN (HPF)</md:title>
  <md:abstract/>
  <md:uuid>02aa60df-1c01-467f-891b-9cb8bf30bc3e</md:uuid>
</metadata>

<content>
      <para id="id1164834826087">In March 1992, the High Performance Fortran Forum (HPFF) began meeting to discuss and define a set of additions to FORTRAN 90 to make it more practical for use in a scalable computing environment. The plan was to develop a specification within the calendar year so that vendors could quickly begin to implement the standard. The scope of the effort included the following:</para>
      <list id="id1164830261521" list-type="bulleted"><item>Identify scalars and arrays that will be distributed across a parallel machine.</item>
        <item>Say how they will be distributed. Will they be strips, blocks, or something else?</item>
        <item>Specify how these variables will be aligned with respect to one another.</item>
        <item>Redistribute and realign data structures at runtime.</item>
        <item>Add a <code>FORALL</code> control construct for parallel assignments that are difficult or impossible to construct using FORTRAN 90's array syntax.</item>
        <item>Make improvements to the FORTRAN 90 <code>WHERE</code> control construct.</item>
        <item>Add intrinsic functions for common parallel operations.</item>
      </list>
      <para id="id6012358">There were several sources of inspiration for the HPF effort. Layout directives were already part of the FORTRAN 90 programming environment for some SIMD computers (i.e., the CM-2). Also, PVM, the first portable message-passing environment, had been released a year earlier, and users had a year of experience trying to decompose by hand programs. They had developed some basic usable techniques for data decomposition that worked very well but required far too much bookkeeping.<footnote id="id1164828591962">As we shall soon see.</footnote></para>
      <para id="id1164830450196">The HPF effort brought together a diverse set of interests from all the major high performance computing vendors. Vendors representing all the major architectures were represented. As a result HPF was designed to be implemented on nearly all types of architectures.</para>
      <para id="id1164831408870">There is an effort underway to produce the next FORTRAN standard: FORTRAN 95. FORTRAN 95 is expected to adopt some but not all of the HPF modifications.</para>
      <section id="id1164837457970">
        <title>Programming in HPF</title>
        <para id="id1164833731599">At its core, HPF includes FORTRAN 90. If a FORTRAN 90 program were run through an HPF compiler, it must produce the same results as if it were run through a FORTRAN 90 compiler. Assuming an HPF program only uses FORTRAN 90 constructs and HPF directives, a FORTRAN 90 compiler could ignore the directives, and it should produce the same results as an HPF compiler.</para>
        <para id="id1164829716842">As the user adds directives to the program, the semantics of the program are not changed. If the user completely misunderstands the application and inserts extremely ill-conceived directives, the program produces correct results very slowly. An HPF compiler doesn't try to "improve on" the user's directives. It assumes the programmer is omniscient.<footnote id="id1164834575318">Always a safe assumption.</footnote></para>
        <para id="id1164836162368">Once the user has determined how the data will be distributed across the processors, the HPF compiler attempts to use the minimum communication necessary and overlaps communication with computation whenever possible. HPF generally uses an "owner computes" rule for the placement of the computations. A particular element in an array is computed on the processor that stores that array element.</para>
        <para id="id1164829092072">All the necessary data to perform the computation is gathered from remote processors, if necessary, to perform the computation. If the programmer is clever in decomposition and alignment, much of the data needed will be from the local memory rather then a remote memory. The HPF compiler is also responsible for allocating any temporary data structures needed to support communications at runtime.</para>
        <para id="id1164839057470">In general, the HPF compiler is not magic - it simply does a very good job with the communication details when the programmer can design a good data decomposition. At the same time, it retains portability with the single CPU and shared uniform memory systems using FORTRAN 90.</para>
      </section>
      <section id="id4211635">
        <title>HPF data layout directives</title>
        <para id="id1164835752713">Perhaps the most important contributions of HPF are its data layout directives. Using these directives, the programmer can control how data is laid out based on the programmer's knowledge of the data interactions. An example directive is as follows:</para>
        <code id="id1164828551836" display="block"><newline/>
            REAL*4 ROD(10)
      !HPF$ DISTRIBUTE ROD(BLOCK)
    </code>
        
        <para id="id1164829731642">The <code display="inline">!HPF$</code> prefix would be a comment to a non-HPF compiler and can safely be ignored by a straight FORTRAN 90 compiler. The <code display="inline">DISTRIBUTE</code> directive indicates that the <code display="inline">ROD</code> array is to be distributed across multiple processors. If this directive is not used, the <code display="inline">ROD</code> array is allocated on one processor and communicated to the other processors as necessary. There are several distributions that can be done in each dimension:</para>
        <code id="id1164828300404" display="block"><newline/>
             REAL*4 BOB(100,100,100),RICH(100,100,100)
      !HPF$ DISTRIBUTE BOB(BLOCK,CYCLIC,*)
      !HPF$ DISTRIBUTE RICH(CYCLIC(10))
    </code>
        <para id="id1164830374936">These distributions operate as follows:</para>
        <list id="id1164828108163" list-type="labeled-item"><item><code display="inline">BLOCK</code> The array is distributed across the processors using contiguous blocks of the index value. The blocks are made as large as possible.</item>
          <item><code display="inline">CYCLIC</code> The array is distributed across the processors, mapping each successive element to the "next" processor, and when the last processor is reached, allocation starts again on the first processor.</item>
          <item><code display="inline">CYCLIC(n)</code> The array is distributed the same as <code>CYCLIC</code> except that <code>n</code> successive elements are placed on each processor before moving on to the next processor.</item>
        </list>
        <note id="id1164828991306" type="Note">All the elements in that dimension are placed on the same processor. This is most useful for multidimensional arrays.</note>
        <para id="id1164830243583">
          <figure id="id1164835082651"><title>Distributing array elements to processors</title><media id="id1164835082651_media" alt="This figure shows three grids of numbered boxes, with three lines of code above each grid.">
              <image mime-type="image/png" src="../../media/graphics1-b194.png" id="id1164835082651__onlineimage" height="301" width="600"/>
            </media>
            
          <!--Figure 13:5--></figure>
        </para>
        <para id="id1164836411572"><link target-id="id1164835082651"/> shows how the elements of a simple array would be mapped onto three processors with different directives. </para>
        <para id="id1164838002243">It must allocate four elements to Processors 1 and 2 because there is no Processor 4 available for the leftover element if it allocated three elements to Processors 1 and 2. In <link target-id="id1164835082651"/>, the elements are allocated on successive processors, wrapping around to Processor 1 after the last processor. In <link target-id="id1164835082651"/>, using a chunk size with <code display="inline">CYCLIC</code> is a compromise between pure <code display="inline">BLOCK</code> and pure <code display="inline">CYCLIC</code>.</para>
        <para id="id1164829475340">To explore the use of the <code display="inline">*</code>, we can look at a simple two-dimensional array mapped onto four processors. In <link target-id="id1164842650911"/>, we show the array layout and each cell indicates which processor will hold the data for that cell in the two-dimensional array. In <link target-id="id1164842650911"/>, the directive decomposes in both dimensions simultaneously. This approach results in roughly square patches in the array. However, this may not be the best approach. In the following example, we use the <code display="inline">*</code> to indicate that we want all the elements of a particular column to be allocated on the same processor. So, the column values equally distribute the columns across the processors. Then, all the rows in each column follow where the column has been placed. This allows unit stride for the on-processor portions of the computation and is beneficial in some applications. The <code display="inline">*</code> syntax is also called <code display="inline">on-processor</code> distribution.</para>
        <para id="id1164828999244">
          <figure id="id1164842650911"><title>Two-dimensional distributions</title><media id="id1164842650911_media" alt="This figure shows two grids of numbered boxes. Both are titled with two lines of code. The grid on the left, with code (Block, Block), has sixteen boxes, four boxes each numbered 1, 2, 3, and 4, and the numbers are organized in quadrants. The grid on the right, with code (*, block), has sixteen boxes, four boxes each numbered 1, 2, 3, and 4, and the numbers are organized in columns.">
              <image mime-type="image/png" src="../../media/graphics2-96dd.png" id="id1164842650911__onlineimage" height="266" width="599"/>
            </media>
            
          <!--figure 13-6--></figure>
        </para>
        <para id="id1164829058985">When dealing with more than one data structure to perform a computation, you can either separately distribute them or use the <code>ALIGN</code> directive to ensure that corresponding elements of the two data structures are to be allocated together. In the following example, we have a plate array and a scaling factor that must be applied to each column of the plate during the computation:</para>
        <code id="id1164835322129" display="block"><newline/>
            DIMENSION PLATE(200,200),SCALE(200)
      !HPF$ DISTRIBUTE PLATE(*,BLOCK)
      !HPF$ ALIGN SCALE(I) WITH PLATE(J,I)
    </code>
        <para id="id1164829560388">Or:</para>
        <code id="id1164833092584" display="block"><newline/>
            DIMENSION PLATE(200,200),SCALE(200)
      !HPF$ DISTRIBUTE PLATE(*,BLOCK)
      !HPF$ ALIGN SCALE(:) WITH PLATE(*,:)
    </code>
        <para id="id1164836125505">In both examples, the <code display="inline">PLATE</code> and the <code display="inline">SCALE</code> variables are allocated to the same processors as the corresponding columns of <code display="inline">PLATE</code>. The <code display="inline">*</code> and <code display="inline">:</code> syntax communicate the same information. When <code display="inline">*</code> is used, that dimension is collapsed, and it doesn't participate in the distribution. When the <code display="inline">:</code> is used, it means that dimension follows the corresponding dimension in the variable that has already been distributed.</para>
        <para id="id1164828247321">You could also specify the layout of the <code display="inline">SCALE</code> variable and have the <code display="inline">PLATE</code> variable "follow" the layout of the <code display="inline">SCALE</code> variable:</para>
        <code id="id1164833634303" display="block"><newline/>
            DIMENSION PLATE(200,200),SCALE(200)
      !HPF$ DISTRIBUTE SCALE(BLOCK)
      !HPF$ ALIGN PLATE(J,I) WITH SCALE(I)
    </code>
        <para id="id1164828265392">You can put simple arithmetic expressions into the <code display="inline">ALIGN</code> directive subject to some limitations. Other directives include:</para>
        <list id="id1164838117358" list-type="labeled-item"><item><code>PROCESSORS</code> Allows you to create a shape of the processor configuration that can be used to align other data structures.</item>
          <item><code>REDISTRIBUTE and REALIGN</code> Allow you to dynamically reshape data structures at runtime as the communication patterns change during the course of the run.</item>
          <item><code>TEMPLATE</code> Allows you to create an array that uses no space. Instead of distributing one data structure and aligning all the other data structures, some users will create and distribute a template and then align all of the real data structures to that template.</item>
        </list>
        <para id="id1164835159301">The use of directives can range from very simple to very complex. In some situations, you distribute the one large shared structure, align a few related structures and you are done. In other situations, programmers attempt to optimize communications based on the topology of the interconnection network (hypercube, multi-stage interconnection network, mesh, or toroid) using very detailed directives. They also might carefully redistribute the data at the various phases of the computation.</para>
        <para id="id1164828929336">Hopefully your application will yield good performance without too much effort.</para>
      </section>
      <section id="id1164828096858">
        <title>HPF control structures</title>
        <para id="id1164829629319">While the HPF designers were in the midst of defining a new language, they set about improving on what they saw as limitations in FORTRAN 90. Interestingly, these modifications are what is being considered as part of the new FORTRAN 95 standard.</para>
        <para id="id1164828602969">The <code display="inline">FORALL</code> statement allows the user to express simple iterative operations that apply to the entire array without resorting to a do-loop (remember, do-loops force order). For example:</para>
        <code id="id1164830281879" display="block"><newline/>
      FORALL (I=1:100, J=1:100) A(I,J) = I + J
    </code>
        <para id="id1164839855069">This can be expressed in native FORTRAN 90 but it is rather ugly, counterintuitive, and prone to error.</para>
        <para id="id1164830205681">Another control structure is the ability to declare a function as "PURE." A PURE function has no side effects other than through its parameters. The programmer is guaranteeing that a PURE function can execute simultaneously on many processors with no ill effects. This allows HPF to assume that it will only operate on local data and does not need any data communication during the duration of the function execution. The programmer can also declare which parameters of the function are input parameters, output parameters, and input-output parameters.</para>
      </section>
      <section id="id1164828556012">
        <title>HPF intrinsics</title>
        <para id="id1164830191541">The companies who marketed SIMD computers needed to come up with significant tools to allow efficient collective operations across all the processors. A perfect example of this is the SUM operation. To <code display="inline">SUM</code> the value of an array spread across N processors, the simplistic approach takes N steps. However, it is possible to accomplish it in log(N) steps using a technique called <emphasis effect="italics">parallel-prefix-sum</emphasis>. By the time HPF was in development, a number of these operations had been identified and implemented. HPF took the opportunity to define standardized syntax for these operations.</para>
        <para id="id1164828569370">A sample of these operations includes:</para>
        <list id="id1164829526981" list-type="labeled-item"><item><code display="inline">SUM_PREFIX </code>Performs various types of parallel-prefix summations.</item>
          <item><code display="inline">ALL_SCATTER</code> Distributes a single value to a set of processors.</item>
          <item><code display="inline">GRADE_DOWN</code> Sorts into decreasing order.</item>
          <item><code display="inline">IANY</code> Computes the logical OR of a set of values.</item>
        </list>
        <para id="id1164838870644">While there are a large number of these intrinsic functions, most applications use only a few of the operations.</para>
      </section>
      <section id="id1164829345417">
        <title>HPF extrinsics</title>
        <para id="id1164829591592">In order to allow the vendors with diverse architectures to provide their particular advantage, HPF included the capability to link "extrinsic" functions. These functions didn't need to be written in FORTRAN 90/HPF and performed a number of vendor-supported capabilities. This capability allowed users to perform such tasks as the creation of hybrid applications with some HPF and some message passing.</para>
        <para id="id1518379">High performance computing programmers always like the ability to do things their own way in order to eke out that last drop of performance.</para>
      </section>
      <section id="id1164839517159">
        <title>Heat Flow in HPF</title>
        <para id="id1164837151368">To port our heat flow application to HPF, there is really only a single line of code that needs to be added. In the example below, we've changed to a larger two-dimensional array:</para>
        <code id="id1164830326703" display="block"><newline/>
              INTEGER PLATESIZ,MAXTIME 
              PARAMETER(PLATESIZ=2000,MAXTIME=200)
      !HPF$   DISTRIBUTE PLATE(*,BLOCK)
              REAL*4 PLATE(PLATESIZ,PLATESIZ) 
              INTEGER TICK
              PLATE = 0.0
    
      * Add Boundaries
              PLATE(1,:) = 100.0
              PLATE(PLATESIZ,:) = -40.0
              PLATE(:,PLATESIZ) = 35.23
              PLATE(:,1) = 4.5
    
              DO TICK = 1,MAXTIME
                PLATE(2:PLATESIZ-1,2:PLATESIZ-1) = (
          +       PLATE(1:PLATESIZ-2,2:PLATESIZ-1) +
          +       PLATE(3:PLATESIZ-0,2:PLATESIZ-1) +
          +       PLATE(2:PLATESIZ-1,1:PLATESIZ-2) +
          +       PLATE(2:PLATESIZ-1,3:PLATESIZ-0) ) / 4.0
                PRINT 1000,TICK, PLATE(2,2)
      1000      FORMAT('TICK = ',I5, F13.8) 
              ENDDO
      *
              END
    </code>
        <para id="id1164828977967">You will notice that the HPF directive distributes the array columns using the <code display="inline">BLOCK</code> approach, keeping all the elements within a column on a single processor. At first glance, it might appear that (<code display="inline">BLOCK</code>,<code display="inline">BLOCK</code>) is the better distribution. However, there are two advantages to a (<code display="inline">*</code>,<code display="inline">BLOCK</code>) distribution. First, striding down a column is a unit-stride operation and so you might just as well process an entire column. The more significant aspect of the distribution is that a (<code display="inline">BLOCK</code>,<code display="inline">BLOCK</code>) distribution forces each processor to communicate with up to eight other processors to get its neighboring values. Using the (*,<code display="inline">BLOCK</code>) distribution, each processor will have to exchange data with at most two processors each time step.</para>
        <para id="id1164829584398">When we look at PVM, we will look at this same program implemented in a SPMD-style message-passing fashion. In that example, you will see some of the details that HPF must handle to properly execute this code. After reviewing that code, you will probably choose to implement all of your future heat flow applications in HPF!</para>
      </section>
      <section id="id1164828192713">
        <title>HPF Summary</title>
        <para id="id1164828979135">In some ways, HPF has been good for FORTRAN 90. Companies such as IBM with its SP-1 needed to provide some high-level language for those users who didn't want to write message-passing codes. Because of this, IBM has invested a great deal of effort in implementing and optimizing HPF. Interestingly, much of this effort will directly benefit the ability to develop more sophisticated FORTRAN 90 compilers. The extensive data flow analysis required to minimize communications and manage the dynamic data structures will carry over into FORTRAN 90 compilers even without using the HPF directives.</para>
        <para id="id1164833969105">Time will tell if the HPF data distribution directives will no longer be needed and compilers will be capable of performing sufficient analysis of straight FORTRAN 90 code to optimize data placement and movement.</para>
        <para id="id1164831628856">In its current form, HPF is an excellent vehicle for expressing the highly data-parallel, grid-based applications. Its weaknesses are irregular communications and dynamic load balancing. A new effort to develop the next version of HPF is under- way to address some of these issues. Unfortunately, it is more difficult to solve these runtime problems while maintaining good performance across a wide range of architectures.</para>
      </section>
  </content>
</document>
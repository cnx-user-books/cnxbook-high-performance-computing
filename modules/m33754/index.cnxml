<document xmlns="http://cnx.rice.edu/cnxml">
  <title>Explicity Parallel Languages</title>
<metadata xmlns:md="http://cnx.rice.edu/mdml">
  <md:content-id>m33754</md:content-id>
  <md:title>Explicity Parallel Languages</md:title>
  <md:abstract/>
  <md:uuid>534fe98b-a296-4407-b3c7-99cf048637c6</md:uuid>
</metadata>

<content>
      <para id="id1168671491532">As we've seen throughout this book, one of biggest tuning challenges is getting the compiler to recognize that a particular code segment can be parallelized. This is particularly true for numerical codes, where the potential payback is greatest. Think about this: if you know that something is parallel, why should there be any difficulty getting the compiler to recognize it? Why can't you just write it down, and have the compiler say "Yes, this is to be done in parallel."</para>
      <para id="id1168668903689">The problem is that the most commonly used languages don't offer any constructs for expressing parallel computations. You are forced to express yourself in primitive terms, as if you were a caveman with a grand thought but no vocabulary to voice it. This is particularly true of FORTRAN and C. They do not support a notion of parallel computations, which means that programmers must reduce calculations to sequential steps. That sounds cumbersome, but most programmers do it so naturally that they don't even realize how good they are at it.</para>
      <para id="id1168676370835">For example, let's say we want to add two vectors, A and B. How would we do it? We would probably write a little loop without a moment's thought:</para>
      <code id="id1168675598027" display="block"><newline/>
      DO I=1,N
        C(I) = A(I) + B(I)
      END DO
    </code>
      <para id="id1168668394184">This seems reasonable, but look what happened. We imposed an order on the calculations! Wouldn't it be enough to say "C gets A plus B"? That would free the compiler to add the vectors using any hardware at its disposal, using any method it likes. This is what parallel languages are about. They seek to supply primitives suitable for expressing parallel computations.</para>
      <para id="id8608312">New parallel languages aren't being proposed as rapidly as they were in the mid-1980s. Developers have realized that you can come up with a wonderful scheme, but if it isn't compatible with FORTRAN or C, few people will care about it. The reason is simple: there are billions of lines of C and FORTRAN code, but only a few lines of <emphasis effect="italics">Fizgibbet</emphasis>, or whatever it is you call your new parallel language. Because of the predominance of C and FORTRAN, the most significant parallel language activities today seek to extend those languages, thus protecting the 20 or 30 years of investment in programs already written.<footnote id="id9011300">One of the more significant efforts in the area of completely new languages is Streams and Iteration in a Single Assignment Language (SISAL). It's a data flow language that can easily integrate FORTRAN and C modules. The most interesting aspects of SISAL are the number of large computational codes that were ported to SISAL and the fact that the SISAL proponents generally compared their performance to the FORTRAN and C performance of the same applications.</footnote> It is too tempting for the developers of a new language to test their language on the eight-queens problem and the game of life, get good results, then declare it ready for prime time and begin waiting for the hordes of programmers converting to their particular language.</para>
  </content>
</document>